{
   "cells": [
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "e93c694c",
         "metadata": {
            "execution": {
               "iopub.execute_input": "2025-05-18T09:14:05.531482Z",
               "iopub.status.busy": "2025-05-18T09:14:05.531217Z",
               "iopub.status.idle": "2025-05-18T09:14:19.573295Z",
               "shell.execute_reply": "2025-05-18T09:14:19.572666Z"
            },
            "papermill": {
               "duration": 14.048355,
               "end_time": "2025-05-18T09:14:19.574629",
               "exception": false,
               "start_time": "2025-05-18T09:14:05.526274",
               "status": "completed"
            },
            "tags": []
         },
         "outputs": [],
         "source": [
            "from typing import Optional\n",
            "import torch\n",
            "from torch import nn\n",
            "from torch.nn import functional as F\n",
            "from torchvision import datasets\n",
            "from torchvision.transforms import v2 as transforms\n",
            "import numpy as np\n",
            "import wandb\n",
            "import time\n",
            "import matplotlib.pyplot as plt\n",
            "import pandas as pd\n",
            "from sklearn.preprocessing import StandardScaler"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "4e0e8ed5",
         "metadata": {
            "execution": {
               "iopub.execute_input": "2025-05-18T09:14:19.582410Z",
               "iopub.status.busy": "2025-05-18T09:14:19.581782Z",
               "iopub.status.idle": "2025-05-18T09:14:19.585362Z",
               "shell.execute_reply": "2025-05-18T09:14:19.584640Z"
            },
            "papermill": {
               "duration": 0.00832,
               "end_time": "2025-05-18T09:14:19.586495",
               "exception": false,
               "start_time": "2025-05-18T09:14:19.578175",
               "status": "completed"
            },
            "tags": []
         },
         "outputs": [],
         "source": [
            "generator = torch.Generator().manual_seed(42)\n",
            "np.random.seed(42)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "96ee072c",
         "metadata": {
            "execution": {
               "iopub.execute_input": "2025-05-18T09:14:19.593596Z",
               "iopub.status.busy": "2025-05-18T09:14:19.593386Z",
               "iopub.status.idle": "2025-05-18T09:14:19.607312Z",
               "shell.execute_reply": "2025-05-18T09:14:19.606819Z"
            },
            "papermill": {
               "duration": 0.018665,
               "end_time": "2025-05-18T09:14:19.608315",
               "exception": false,
               "start_time": "2025-05-18T09:14:19.589650",
               "status": "completed"
            },
            "tags": []
         },
         "outputs": [],
         "source": [
            "\n",
            "class GaussianVariational(nn.Module):\n",
            "\n",
            "    def __init__(self, mu: torch.Tensor, rho: torch.Tensor) -> None:\n",
            "        super().__init__()\n",
            "\n",
            "        self.mu = nn.Parameter(mu)\n",
            "        self.rho = nn.Parameter(rho)\n",
            "\n",
            "        self.w = None\n",
            "        self.sigma = None\n",
            "\n",
            "        self.normal = torch.distributions.Normal(0, 1)\n",
            "\n",
            "    def sample(self) -> torch.Tensor:\n",
            "        device = self.mu.device\n",
            "        epsilon = self.normal.sample(self.mu.size()).to(device)\n",
            "        self.sigma = torch.log1p(torch.exp(self.rho))\n",
            "        self.w = self.mu + self.sigma * epsilon\n",
            "\n",
            "        return self.w\n",
            "\n",
            "    def log_posterior(self) -> torch.Tensor:\n",
            "        assert self.w is not None\n",
            "\n",
            "        log_const = np.log(np.sqrt(2 * np.pi))\n",
            "        log_exp = ((self.w - self.mu) ** 2) / (2 * self.sigma ** 2)\n",
            "        log_posterior = -log_const - torch.log(self.sigma) - log_exp\n",
            "\n",
            "        return log_posterior.sum()\n",
            "\n",
            "\n",
            "class ScaleMixture(nn.Module):\n",
            "\n",
            "    def __init__(self, pi: float, sigma1: float, sigma2: float) -> None:\n",
            "        super().__init__()\n",
            "\n",
            "        self.pi = pi\n",
            "        self.sigma1 = sigma1\n",
            "        self.sigma2 = sigma2\n",
            "\n",
            "        self.normal1 = torch.distributions.Normal(0, sigma1)\n",
            "        self.normal2 = torch.distributions.Normal(0, sigma2)\n",
            "\n",
            "    def log_prior(self, w: torch.Tensor) -> torch.Tensor:\n",
            "        likelihood_n1 = torch.exp(self.normal1.log_prob(w))\n",
            "        likelihood_n2 = torch.exp(self.normal2.log_prob(w))\n",
            "\n",
            "        p_scalemixture = self.pi * likelihood_n1 + (1 - self.pi) * likelihood_n2\n",
            "        log_prob = torch.log(p_scalemixture).sum()\n",
            "\n",
            "        return log_prob\n",
            "\n",
            "\n",
            "class BayesianModule(nn.Module):\n",
            "    pass\n",
            "\n",
            "\n",
            "class BayesLinear(BayesianModule):\n",
            "\n",
            "    def __init__(self,\n",
            "                 in_features: int,\n",
            "                 out_features: int,\n",
            "                 prior_pi: Optional[float] = 0.5,\n",
            "                 prior_sigma1: Optional[float] = 1.0,\n",
            "                 prior_sigma2: Optional[float] = 0.0025) -> None:\n",
            "        super().__init__()\n",
            "\n",
            "        w_mu = torch.empty(out_features, in_features).uniform_(-0.2, 0.2, generator=generator)\n",
            "        w_rho = torch.empty(out_features, in_features).uniform_(-5.0, -4.0, generator=generator)\n",
            "\n",
            "        bias_mu = torch.empty(out_features).uniform_(-0.2, 0.2, generator=generator)\n",
            "        bias_rho = torch.empty(out_features).uniform_(-5.0, -4.0, generator=generator)\n",
            "\n",
            "        self.w_posterior = GaussianVariational(w_mu, w_rho)\n",
            "        self.bias_posterior = GaussianVariational(bias_mu, bias_rho)\n",
            "\n",
            "        self.w_prior = ScaleMixture(prior_pi, prior_sigma1, prior_sigma2)\n",
            "        self.bias_prior = ScaleMixture(prior_pi, prior_sigma1, prior_sigma2)\n",
            "\n",
            "        self.kl_divergence = 0.0\n",
            "\n",
            "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
            "        w = self.w_posterior.sample()\n",
            "        b = self.bias_posterior.sample()\n",
            "\n",
            "        w_log_prior = self.w_prior.log_prior(w)\n",
            "        b_log_prior = self.bias_prior.log_prior(b)\n",
            "\n",
            "        w_log_posterior = self.w_posterior.log_posterior()\n",
            "        b_log_posterior = self.bias_posterior.log_posterior()\n",
            "\n",
            "        total_log_prior = w_log_prior + b_log_prior\n",
            "        total_log_posterior = w_log_posterior + b_log_posterior\n",
            "        self.kl_divergence = total_log_posterior - total_log_prior\n",
            "\n",
            "        return F.linear(x, w, b)\n",
            "\n",
            "\n",
            "def minibatch_weight(batch_idx: int, num_batches: int) -> float:\n",
            "    return 1 / num_batches\n",
            "\n",
            "\n",
            "def variational_estimator(nn_class):\n",
            "\n",
            "    @property\n",
            "    def kl_divergence(self):\n",
            "        kl = 0\n",
            "        for module in self.modules():\n",
            "            if isinstance(module, BayesianModule):\n",
            "                kl += module.kl_divergence\n",
            "\n",
            "        return kl\n",
            "\n",
            "    setattr(nn_class, \"kl_divergence\", kl_divergence)\n",
            "\n",
            "    def sample_elbo(self, inputs, labels, criterion, num_samples, complexity_cost_weight=1):\n",
            "        loss = 0\n",
            "        for _ in range(num_samples):\n",
            "            outputs = self(inputs)\n",
            "            contr1 = criterion(outputs, labels)\n",
            "            contr2 = self.kl_divergence * complexity_cost_weight\n",
            "            # print(f\"contr1: {contr1}, contr2: {contr2}\")\n",
            "            loss += contr1 + contr2\n",
            "        return loss / num_samples\n",
            "\n",
            "    setattr(nn_class, \"sample_elbo\", sample_elbo)\n",
            "\n",
            "    return nn_class"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "e01c1ecd",
         "metadata": {
            "execution": {
               "iopub.execute_input": "2025-05-18T09:14:19.615051Z",
               "iopub.status.busy": "2025-05-18T09:14:19.614848Z",
               "iopub.status.idle": "2025-05-18T09:14:19.682904Z",
               "shell.execute_reply": "2025-05-18T09:14:19.682183Z"
            },
            "papermill": {
               "duration": 0.072543,
               "end_time": "2025-05-18T09:14:19.683925",
               "exception": false,
               "start_time": "2025-05-18T09:14:19.611382",
               "status": "completed"
            },
            "tags": []
         },
         "outputs": [],
         "source": [
            "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
            "print(f\"Using device: {device}\")"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "11cb55c1",
         "metadata": {
            "papermill": {
               "duration": 0.002852,
               "end_time": "2025-05-18T09:14:19.690025",
               "exception": false,
               "start_time": "2025-05-18T09:14:19.687173",
               "status": "completed"
            },
            "tags": []
         },
         "source": [
            "# MNIST classification"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "7f9df508",
         "metadata": {
            "execution": {
               "iopub.execute_input": "2025-05-18T09:14:19.697023Z",
               "iopub.status.busy": "2025-05-18T09:14:19.696768Z",
               "iopub.status.idle": "2025-05-18T09:14:19.701757Z",
               "shell.execute_reply": "2025-05-18T09:14:19.701059Z"
            },
            "papermill": {
               "duration": 0.009841,
               "end_time": "2025-05-18T09:14:19.702823",
               "exception": false,
               "start_time": "2025-05-18T09:14:19.692982",
               "status": "completed"
            },
            "tags": []
         },
         "outputs": [],
         "source": [
            "@variational_estimator\n",
            "class MNISTModel(nn.Module):\n",
            "\n",
            "    def __init__(self, in_features=28 * 28, out_features=10, prior_sigma_1=0.1, prior_sigma_2=0.4, prior_pi=1):\n",
            "        super().__init__()\n",
            "\n",
            "        self.layers = nn.Sequential(\n",
            "            BayesLinear(\n",
            "                in_features,\n",
            "                1200,\n",
            "                prior_pi,\n",
            "                prior_sigma_1,\n",
            "                prior_sigma_2\n",
            "            ),\n",
            "            nn.ReLU(),\n",
            "            BayesLinear(\n",
            "                1200,\n",
            "                1200,\n",
            "                prior_pi,\n",
            "                prior_sigma_1,\n",
            "                prior_sigma_2\n",
            "            ),\n",
            "            nn.ReLU(),\n",
            "            BayesLinear(\n",
            "                1200,\n",
            "                out_features,\n",
            "                prior_pi,\n",
            "                prior_sigma_1,\n",
            "                prior_sigma_2,\n",
            "            ),\n",
            "            nn.Softmax(dim=1),\n",
            "        )\n",
            "\n",
            "    def forward(self, x):\n",
            "        x = self.layers(x)\n",
            "        # print(x)\n",
            "        return x"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "8801c1a1",
         "metadata": {
            "execution": {
               "iopub.execute_input": "2025-05-18T09:14:19.709645Z",
               "iopub.status.busy": "2025-05-18T09:14:19.709444Z",
               "iopub.status.idle": "2025-05-18T09:14:19.716950Z",
               "shell.execute_reply": "2025-05-18T09:14:19.716399Z"
            },
            "papermill": {
               "duration": 0.012104,
               "end_time": "2025-05-18T09:14:19.717991",
               "exception": false,
               "start_time": "2025-05-18T09:14:19.705887",
               "status": "completed"
            },
            "tags": []
         },
         "outputs": [],
         "source": [
            "def train_one_epoch(model, train_loader, optimizer, criterion, num_samples=1):\n",
            "    model.train()\n",
            "\n",
            "    total_loss = 0\n",
            "\n",
            "    for batch_idx, (data, target) in enumerate(train_loader):\n",
            "        data, target = data.to(device), target.to(device)\n",
            "\n",
            "        optimizer.zero_grad()\n",
            "\n",
            "        kl_weight = minibatch_weight(batch_idx, len(train_loader))\n",
            "\n",
            "        loss = model.sample_elbo(data, target, criterion, num_samples, kl_weight)\n",
            "\n",
            "        loss.backward()\n",
            "        optimizer.step()\n",
            "\n",
            "        total_loss += loss.item()\n",
            "\n",
            "    return total_loss / len(train_loader)\n",
            "\n",
            "\n",
            "def evaluate(model, val_loader, criterion):\n",
            "    model.eval()\n",
            "\n",
            "    total_loss = 0\n",
            "    correct = 0\n",
            "\n",
            "    with torch.no_grad():\n",
            "        for batch_idx, (data, target) in enumerate(val_loader):\n",
            "            data, target = data.to(device), target.to(device)\n",
            "\n",
            "            output = model(data)\n",
            "\n",
            "            preds = torch.argmax(output, 1)\n",
            "            correct += (preds == target).sum().item()\n",
            "\n",
            "            loss = (\n",
            "                criterion(output, target)\n",
            "                + model.kl_divergence * minibatch_weight(batch_idx, len(val_loader))\n",
            "            )\n",
            "            total_loss += loss.item()\n",
            "\n",
            "    total = len(val_loader.dataset)\n",
            "    return total_loss / total, (total - correct) / total\n",
            "\n",
            "\n",
            "def test(model, test_loader):\n",
            "    model.eval()\n",
            "\n",
            "    correct = 0\n",
            "\n",
            "    with torch.no_grad():\n",
            "        for data, target in test_loader:\n",
            "            data, target = data.to(device), target.to(device)\n",
            "\n",
            "            output = model(data)\n",
            "\n",
            "            preds = torch.argmax(output, 1)\n",
            "            correct += (preds == target).sum().item()\n",
            "\n",
            "    total = len(test_loader.dataset)\n",
            "    error = (total - correct) / total\n",
            "\n",
            "    # print(f\"Correct: {correct}/{total} ({correct / total:.2%})\")\n",
            "    return error\n",
            "\n",
            "\n",
            "def train(model, train_loader, val_loader, test_loader, optimizer, criterion, num_epochs, num_samples, use_wandb=False):\n",
            "    for epoch in range(num_epochs):\n",
            "        now = time.time()\n",
            "\n",
            "        train_loss = train_one_epoch(model, train_loader, optimizer, criterion, num_samples)\n",
            "        val_loss, val_error = evaluate(model, val_loader, criterion)\n",
            "        test_error = test(model, test_loader)\n",
            "\n",
            "        elapsed = time.time() - now\n",
            "\n",
            "        if use_wandb:\n",
            "            wandb.log({\n",
            "                \"epoch\": epoch,\n",
            "                \"train_loss\": train_loss,\n",
            "                \"val_loss\": val_loss,\n",
            "                \"val_error\": val_error,\n",
            "                \"test_error\": test_error\n",
            "            })\n",
            "\n",
            "        print(f\"Epoch {epoch + 1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Error: {val_error:.2%}, Test Error: {test_error:.2%}, Time: {elapsed:.2f}s\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "c87e7ebb",
         "metadata": {
            "execution": {
               "iopub.execute_input": "2025-05-18T09:14:19.724639Z",
               "iopub.status.busy": "2025-05-18T09:14:19.724446Z",
               "iopub.status.idle": "2025-05-18T09:14:19.728906Z",
               "shell.execute_reply": "2025-05-18T09:14:19.728346Z"
            },
            "papermill": {
               "duration": 0.008846,
               "end_time": "2025-05-18T09:14:19.729859",
               "exception": false,
               "start_time": "2025-05-18T09:14:19.721013",
               "status": "completed"
            },
            "tags": []
         },
         "outputs": [],
         "source": [
            "def train_mnist(train_loader, val_loader, test_loader, epochs, lr, num_samples, pi, minus_log_sigma1, minus_log_sigma2, use_wandb=False):\n",
            "    sigma1 = np.exp(-minus_log_sigma1)\n",
            "    sigma2 = np.exp(-minus_log_sigma2)\n",
            "\n",
            "    model = MNISTModel(prior_sigma_1=sigma1, prior_sigma_2=sigma2, prior_pi=pi)\n",
            "    model.to(device)\n",
            "\n",
            "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
            "    criterion = nn.CrossEntropyLoss(reduction='sum')\n",
            "\n",
            "    if use_wandb:\n",
            "        run = wandb.init(project=\"asi-paper\", name=\"mnist\")\n",
            "\n",
            "    train(model, train_loader, val_loader, test_loader, optimizer, criterion, epochs, num_samples, use_wandb=use_wandb)\n",
            "\n",
            "    if use_wandb:\n",
            "        run.finish()\n",
            "\n",
            "    return model"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "955153f5",
         "metadata": {
            "execution": {
               "iopub.execute_input": "2025-05-18T09:14:19.736643Z",
               "iopub.status.busy": "2025-05-18T09:14:19.736445Z",
               "iopub.status.idle": "2025-05-18T09:14:24.397298Z",
               "shell.execute_reply": "2025-05-18T09:14:24.396351Z"
            },
            "papermill": {
               "duration": 4.665538,
               "end_time": "2025-05-18T09:14:24.398487",
               "exception": false,
               "start_time": "2025-05-18T09:14:19.732949",
               "status": "completed"
            },
            "tags": []
         },
         "outputs": [],
         "source": [
            "batch_size = 128\n",
            "transform = transforms.Compose([\n",
            "    transforms.ToImage(),\n",
            "    transforms.ToDtype(torch.float32, scale=True),\n",
            "    # transforms.Normalize((0.1307,), (0.3081,)),\n",
            "    transforms.Lambda(lambda x: x.view(28 * 28) / 126.0),\n",
            "])\n",
            "\n",
            "\n",
            "mnist_dataset = datasets.MNIST(\n",
            "    root=\"./mnist\",\n",
            "    download=True,\n",
            "    transform=transform,\n",
            "    train=True\n",
            ")\n",
            "# transformed_data = transform(mnist_dataset.data).to(device)\n",
            "# y = mnist_dataset.targets.to(device)\n",
            "# mnist_dataset = torch.utils.data.TensorDataset(transformed_data, y)\n",
            "\n",
            "test_set = datasets.MNIST(\n",
            "    root=\"./mnist\",\n",
            "    download=True,\n",
            "    transform=transform,\n",
            "    train=False\n",
            ")\n",
            "\n",
            "\n",
            "train_dataset, val_dataset = torch.utils.data.random_split(mnist_dataset, [50_000, 10_000], generator=generator)\n",
            "\n",
            "kwargs = {\n",
            "    'batch_size': batch_size,\n",
            "    'num_workers': 1,\n",
            "    'generator': generator,\n",
            "    'pin_memory': True,\n",
            "}\n",
            "\n",
            "train_loader = torch.utils.data.DataLoader(\n",
            "    train_dataset,\n",
            "    shuffle=True,\n",
            "    **kwargs\n",
            ")\n",
            "val_loader = torch.utils.data.DataLoader(\n",
            "    val_dataset,\n",
            "    shuffle=False,\n",
            "    **kwargs\n",
            ")\n",
            "test_loader = torch.utils.data.DataLoader(\n",
            "    test_set,\n",
            "    shuffle=False,\n",
            "    **kwargs\n",
            ")"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "8fcbe99a",
         "metadata": {
            "papermill": {
               "duration": 0.003816,
               "end_time": "2025-05-18T09:14:24.406597",
               "exception": false,
               "start_time": "2025-05-18T09:14:24.402781",
               "status": "completed"
            },
            "tags": []
         },
         "source": [
            "## Grid search with wandb\n",
            "Uncomment the code below to run a grid search and log the results to wandb."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "ba3cd36d",
         "metadata": {
            "execution": {
               "iopub.execute_input": "2025-05-18T09:14:24.415356Z",
               "iopub.status.busy": "2025-05-18T09:14:24.414916Z",
               "iopub.status.idle": "2025-05-18T09:14:24.418147Z",
               "shell.execute_reply": "2025-05-18T09:14:24.417651Z"
            },
            "papermill": {
               "duration": 0.008688,
               "end_time": "2025-05-18T09:14:24.419128",
               "exception": false,
               "start_time": "2025-05-18T09:14:24.410440",
               "status": "completed"
            },
            "tags": []
         },
         "outputs": [],
         "source": [
            "from kaggle_secrets import UserSecretsClient\n",
            "user_secrets = UserSecretsClient()\n",
            "key = user_secrets.get_secret('wand-api-key-asi')\n",
            "\n",
            "wandb.login(key=key)\n",
            "\n",
            "\n",
            "def train_wrapper():\n",
            "    with wandb.init(project=\"asi-paper\") as run:\n",
            "        model = train_mnist(\n",
            "            train_loader,\n",
            "            val_loader,\n",
            "            test_loader,\n",
            "            epochs=10,\n",
            "            lr=run.config.lr,\n",
            "            num_samples=run.config.sample_nbr,\n",
            "            pi=run.config.pi,\n",
            "            minus_log_sigma1=run.config.min_log_sigma1,\n",
            "            minus_log_sigma2=run.config.min_log_sigma2,\n",
            "            use_wandb=True\n",
            "        )\n",
            "\n",
            "    return model\n",
            "\n",
            "\n",
            "sweep_configuration = {\n",
            "    \"method\": \"bayes\",\n",
            "    \"metric\": {\"goal\": \"minimize\", \"name\": \"val_error\"},\n",
            "    'name': \"sweep-mnist\",\n",
            "    \"parameters\": {\n",
            "        \"lr\": {'values': [1e-3, 1e-4, 1e-5]},\n",
            "        \"sample_nbr\": {'values': [1, 2, 3, 5, 10]},\n",
            "        \"pi\": {'values': [0.25, 0.5, 0.75]},\n",
            "        \"min_log_sigma1\": {'values': [0, 1, 2]},\n",
            "        \"min_log_sigma2\": {'values': [6, 7, 8]},\n",
            "    },\n",
            "}\n",
            "\n",
            "sweep_id = wandb.sweep(sweep=sweep_configuration, project=\"asi-paper\")\n",
            "wandb.agent(sweep_id, function=train_wrapper, count=150)"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "2df0eb61",
         "metadata": {
            "papermill": {
               "duration": 0.003612,
               "end_time": "2025-05-18T09:14:24.426625",
               "exception": false,
               "start_time": "2025-05-18T09:14:24.423013",
               "status": "completed"
            },
            "tags": []
         },
         "source": [
            "## Manual training\n",
            "Uncomment the code below to train the model with specified hyperparameters and save the model checkpoint."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "22e2af5b",
         "metadata": {
            "execution": {
               "iopub.execute_input": "2025-05-18T09:14:24.434954Z",
               "iopub.status.busy": "2025-05-18T09:14:24.434770Z",
               "iopub.status.idle": "2025-05-18T10:24:20.330538Z",
               "shell.execute_reply": "2025-05-18T10:24:20.329903Z"
            },
            "papermill": {
               "duration": 4195.901559,
               "end_time": "2025-05-18T10:24:20.331982",
               "exception": false,
               "start_time": "2025-05-18T09:14:24.430423",
               "status": "completed"
            },
            "tags": []
         },
         "outputs": [],
         "source": [
            "# from kaggle_secrets import UserSecretsClient\n",
            "# user_secrets = UserSecretsClient()\n",
            "# key = user_secrets.get_secret('wand-api-key-asi')\n",
            "\n",
            "# wandb.login(key=key)\n",
            "\n",
            "# model = train_mnist(train_loader, val_loader, test_loader, epochs=200, lr=1e-3, num_samples=1, pi=0.5, minus_log_sigma1=0, minus_log_sigma2=6, use_wandb=False)\n",
            "# torch.save(model.state_dict(), \"mnist_model.pt\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "cba3dbf0",
         "metadata": {
            "execution": {
               "iopub.execute_input": "2025-05-18T10:24:20.357909Z",
               "iopub.status.busy": "2025-05-18T10:24:20.357557Z",
               "iopub.status.idle": "2025-05-18T10:24:20.361079Z",
               "shell.execute_reply": "2025-05-18T10:24:20.360555Z"
            },
            "papermill": {
               "duration": 0.017539,
               "end_time": "2025-05-18T10:24:20.362116",
               "exception": false,
               "start_time": "2025-05-18T10:24:20.344577",
               "status": "completed"
            },
            "tags": []
         },
         "outputs": [],
         "source": [
            "# model = MNISTModel(prior_sigma_1=np.exp(-1), prior_sigma_2=np.exp(-7), prior_pi=0.75)\n",
            "# model.to(device)\n",
            "# model.load_state_dict(torch.load(\"mnist_model.pt\"))"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "05676d69",
         "metadata": {
            "papermill": {
               "duration": 0.011819,
               "end_time": "2025-05-18T10:24:20.385892",
               "exception": false,
               "start_time": "2025-05-18T10:24:20.374073",
               "status": "completed"
            },
            "tags": []
         },
         "source": [
            "# Regression curves"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "3f8515f2",
         "metadata": {
            "execution": {
               "iopub.execute_input": "2025-05-18T10:24:20.410704Z",
               "iopub.status.busy": "2025-05-18T10:24:20.410477Z",
               "iopub.status.idle": "2025-05-18T10:24:20.695717Z",
               "shell.execute_reply": "2025-05-18T10:24:20.695169Z"
            },
            "papermill": {
               "duration": 0.298933,
               "end_time": "2025-05-18T10:24:20.696829",
               "exception": false,
               "start_time": "2025-05-18T10:24:20.397896",
               "status": "completed"
            },
            "tags": []
         },
         "outputs": [],
         "source": [
            "def generate_samples(num_samples):\n",
            "    eps = np.random.normal(0, 0.02, num_samples)\n",
            "    x = np.linspace(0, 0.5, num_samples)\n",
            "    y = x + 0.3 * np.sin(2 * np.pi * (x + eps)) + 0.3 * np.sin(4 * np.pi * (x + eps))\n",
            "    return x, y\n",
            "\n",
            "\n",
            "def save_samples(x, y, filename):\n",
            "    df = pd.DataFrame({'x': x, 'y': y})\n",
            "    df.to_csv(filename, index=False)\n",
            "\n",
            "\n",
            "def load_samples(filename):\n",
            "    df = pd.read_csv(filename)\n",
            "    x = df['x'].values\n",
            "    y = df['y'].values\n",
            "    return x, y\n",
            "\n",
            "\n",
            "def plot_samples(x, y):\n",
            "    plt.figure(figsize=(10, 5))\n",
            "    plt.plot(x, y, 'kx', label='Generated Samples')\n",
            "    plt.title('Generated Samples')\n",
            "    plt.xlabel('x')\n",
            "    plt.ylabel('y')\n",
            "    plt.legend()\n",
            "    plt.show()\n",
            "\n",
            "\n",
            "# x, y = generate_samples(1000)\n",
            "# save_samples(x, y, 'regression_samples.csv')\n",
            "\n",
            "\n",
            "x, y = load_samples('regression_samples.csv')\n",
            "plot_samples(x, y)\n",
            "\n",
            "X_tensor = torch.tensor(x, dtype=torch.float32).view(-1, 1).to(device)\n",
            "y_tensor = torch.tensor(y, dtype=torch.float32).view(-1, 1).to(device)\n",
            "\n",
            "train_dataset = torch.utils.data.TensorDataset(X_tensor[:800], y_tensor[:800])\n",
            "val_dataset = torch.utils.data.TensorDataset(X_tensor[800:], y_tensor[800:])\n",
            "\n",
            "\n",
            "kwargs = {\n",
            "    'batch_size': batch_size,\n",
            "    'generator': generator,\n",
            "}\n",
            "\n",
            "train_loader = torch.utils.data.DataLoader(\n",
            "    train_dataset,\n",
            "    shuffle=True,\n",
            "    **kwargs\n",
            ")\n",
            "val_loader = torch.utils.data.DataLoader(\n",
            "    val_dataset,\n",
            "    shuffle=False,\n",
            "    **kwargs\n",
            ")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "a66e7c22",
         "metadata": {
            "execution": {
               "iopub.execute_input": "2025-05-18T10:24:20.723766Z",
               "iopub.status.busy": "2025-05-18T10:24:20.723513Z",
               "iopub.status.idle": "2025-05-18T10:24:20.728128Z",
               "shell.execute_reply": "2025-05-18T10:24:20.727616Z"
            },
            "papermill": {
               "duration": 0.019103,
               "end_time": "2025-05-18T10:24:20.729133",
               "exception": false,
               "start_time": "2025-05-18T10:24:20.710030",
               "status": "completed"
            },
            "tags": []
         },
         "outputs": [],
         "source": [
            "@variational_estimator\n",
            "class RegressionModel(nn.Module):\n",
            "    def __init__(self, in_features=1, out_features=1, prior_sigma_1=0.1, prior_sigma_2=0.4, prior_pi=1):\n",
            "        super().__init__()\n",
            "\n",
            "        self.layers = nn.Sequential(\n",
            "            BayesLinear(\n",
            "                in_features,\n",
            "                200,\n",
            "                prior_pi,\n",
            "                prior_sigma_1,\n",
            "                prior_sigma_2\n",
            "            ),\n",
            "            nn.ReLU(),\n",
            "            BayesLinear(\n",
            "                200,\n",
            "                200,\n",
            "                prior_pi,\n",
            "                prior_sigma_1,\n",
            "                prior_sigma_2\n",
            "            ),\n",
            "            nn.ReLU(),\n",
            "            BayesLinear(\n",
            "                200,\n",
            "                out_features,\n",
            "                prior_pi,\n",
            "                prior_sigma_1,\n",
            "                prior_sigma_2,\n",
            "            ),\n",
            "        )\n",
            "\n",
            "    def forward(self, x):\n",
            "        x = self.layers(x)\n",
            "        return x"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "9c6ad1b4",
         "metadata": {
            "execution": {
               "iopub.execute_input": "2025-05-18T10:24:20.755128Z",
               "iopub.status.busy": "2025-05-18T10:24:20.754923Z",
               "iopub.status.idle": "2025-05-18T10:24:20.760930Z",
               "shell.execute_reply": "2025-05-18T10:24:20.760399Z"
            },
            "papermill": {
               "duration": 0.020355,
               "end_time": "2025-05-18T10:24:20.761940",
               "exception": false,
               "start_time": "2025-05-18T10:24:20.741585",
               "status": "completed"
            },
            "tags": []
         },
         "outputs": [],
         "source": [
            "def evaluate_regression(regressor, X, y, samples=100, std_multiplier=2):\n",
            "    preds = [regressor(X) for _ in range(samples)]\n",
            "    preds = torch.stack(preds)\n",
            "    means = preds.mean(axis=0)\n",
            "    stds = preds.std(axis=0)\n",
            "    ci_upper = means + (std_multiplier * stds)\n",
            "    ci_lower = means - (std_multiplier * stds)\n",
            "    ci_acc = (ci_lower <= y) * (ci_upper >= y)\n",
            "    ci_acc = ci_acc.float().mean()\n",
            "    return ci_acc, (ci_upper >= y).float().mean(), (ci_lower <= y).float().mean()\n",
            "\n",
            "\n",
            "def train_regression(model, train_loader, val_loader, optimizer, criterion, num_epochs, num_samples, use_wandb=False):\n",
            "    for epoch in range(num_epochs):\n",
            "        now = time.time()\n",
            "\n",
            "        train_loss = train_one_epoch(model, train_loader, optimizer, criterion, num_samples)\n",
            "        ci_acc, ci_upper, ci_lower = evaluate_regression(model, val_loader.dataset.tensors[0], val_loader.dataset.tensors[1])\n",
            "\n",
            "        elapsed = time.time() - now\n",
            "\n",
            "        if use_wandb:\n",
            "            wandb.log({\n",
            "                \"epoch\": epoch,\n",
            "                \"train_loss\": train_loss,\n",
            "                \"ci_acc\": ci_acc,\n",
            "                \"ci_upper\": ci_upper,\n",
            "                \"ci_lower\": ci_lower,\n",
            "            })\n",
            "\n",
            "        print(f\"Epoch {epoch + 1}/{num_epochs}, Train Loss: {train_loss:.4f}, CI acc: {ci_acc}, CI upper acc: {ci_upper}, CI lower acc: {ci_lower} Time: {elapsed:.2f}s\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "d8690703",
         "metadata": {
            "execution": {
               "iopub.execute_input": "2025-05-18T10:24:20.788127Z",
               "iopub.status.busy": "2025-05-18T10:24:20.787911Z",
               "iopub.status.idle": "2025-05-18T10:24:20.792244Z",
               "shell.execute_reply": "2025-05-18T10:24:20.791703Z"
            },
            "papermill": {
               "duration": 0.01878,
               "end_time": "2025-05-18T10:24:20.793287",
               "exception": false,
               "start_time": "2025-05-18T10:24:20.774507",
               "status": "completed"
            },
            "tags": []
         },
         "outputs": [],
         "source": [
            "def train_regression_model(train_loader, val_loader, epochs, lr, num_samples, pi, minus_log_sigma1, minus_log_sigma2, use_wandb=False):\n",
            "    sigma1 = np.exp(-minus_log_sigma1)\n",
            "    sigma2 = np.exp(-minus_log_sigma2)\n",
            "\n",
            "    model = RegressionModel(1, 1, prior_sigma_1=sigma1, prior_sigma_2=sigma2, prior_pi=pi)\n",
            "    model.to(device)\n",
            "\n",
            "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
            "    criterion = nn.MSELoss()\n",
            "\n",
            "    # if use_wandb:\n",
            "    #     run = wandb.init(project=\"asi-paper\", name=\"regression\")\n",
            "\n",
            "    train_regression(model, train_loader, val_loader, optimizer, criterion, epochs, num_samples, use_wandb=use_wandb)\n",
            "\n",
            "    # if use_wandb:\n",
            "    #     run.finish()\n",
            "\n",
            "    return model"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "d4535a08",
         "metadata": {
            "execution": {
               "iopub.execute_input": "2025-05-18T10:24:20.819452Z",
               "iopub.status.busy": "2025-05-18T10:24:20.819255Z",
               "iopub.status.idle": "2025-05-18T10:24:20.822730Z",
               "shell.execute_reply": "2025-05-18T10:24:20.822065Z"
            },
            "papermill": {
               "duration": 0.018148,
               "end_time": "2025-05-18T10:24:20.823933",
               "exception": false,
               "start_time": "2025-05-18T10:24:20.805785",
               "status": "completed"
            },
            "tags": []
         },
         "outputs": [],
         "source": [
            "# from kaggle_secrets import UserSecretsClient\n",
            "# user_secrets = UserSecretsClient()\n",
            "# key = user_secrets.get_secret('wand-api-key-asi')\n",
            "\n",
            "# wandb.login(key=key)\n",
            "\n",
            "\n",
            "# def train_wrapper():\n",
            "#     with wandb.init(project=\"asi-paper\") as run:\n",
            "#         model = train_regression_model(\n",
            "#             train_loader,\n",
            "#             val_loader,\n",
            "#             epochs=15,\n",
            "#             lr=run.config.lr,\n",
            "#             num_samples=run.config.sample_nbr,\n",
            "#             pi=run.config.pi,\n",
            "#             minus_log_sigma1=run.config.min_log_sigma1,\n",
            "#             minus_log_sigma2=run.config.min_log_sigma2,\n",
            "#             use_wandb=True\n",
            "#         )\n",
            "\n",
            "#     return model\n",
            "\n",
            "\n",
            "# sweep_configuration = {\n",
            "#     \"method\": \"bayes\",\n",
            "#     \"metric\": {\"goal\": \"maximize\", \"name\": \"ci_acc\"},\n",
            "#     'name': \"sweep-regression\",\n",
            "#     \"parameters\": {\n",
            "#         \"lr\": {'min': 1e-5, 'max': 1e-2},\n",
            "#         \"sample_nbr\": {'min': 1, 'max': 10},\n",
            "#         \"pi\": {'min': 0.25, 'max': 0.75},\n",
            "#         \"min_log_sigma1\": {'min': 0, 'max': 2},\n",
            "#         \"min_log_sigma2\": {'min': 6, 'max': 8},\n",
            "#     },\n",
            "# }\n",
            "\n",
            "# sweep_id = wandb.sweep(sweep=sweep_configuration, project=\"asi-paper\")\n",
            "# wandb.agent(sweep_id, function=train_wrapper)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "c2a195d4",
         "metadata": {
            "execution": {
               "iopub.execute_input": "2025-05-18T10:24:20.850597Z",
               "iopub.status.busy": "2025-05-18T10:24:20.850098Z",
               "iopub.status.idle": "2025-05-18T10:24:20.853205Z",
               "shell.execute_reply": "2025-05-18T10:24:20.852652Z"
            },
            "papermill": {
               "duration": 0.017372,
               "end_time": "2025-05-18T10:24:20.854217",
               "exception": false,
               "start_time": "2025-05-18T10:24:20.836845",
               "status": "completed"
            },
            "tags": []
         },
         "outputs": [],
         "source": [
            "# model = train_regression_model(train_loader, val_loader, epochs=10, lr=1e-3, num_samples=1, pi=0.5, minus_log_sigma1=0, minus_log_sigma2=6)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "76dde1bb",
         "metadata": {
            "execution": {
               "iopub.execute_input": "2025-05-18T10:24:20.880401Z",
               "iopub.status.busy": "2025-05-18T10:24:20.880199Z",
               "iopub.status.idle": "2025-05-18T10:24:20.883325Z",
               "shell.execute_reply": "2025-05-18T10:24:20.882648Z"
            },
            "papermill": {
               "duration": 0.017291,
               "end_time": "2025-05-18T10:24:20.884334",
               "exception": false,
               "start_time": "2025-05-18T10:24:20.867043",
               "status": "completed"
            },
            "tags": []
         },
         "outputs": [],
         "source": [
            "# model.eval()\n",
            "# predicted = model(X_tensor).cpu().detach().numpy()\n",
            "\n",
            "# plt.figure(figsize=(10, 5))\n",
            "# plt.plot(x, y, 'kx', label='Generated Samples')\n",
            "# plt.plot(x, predicted, 'r-', label='Predicted Mean')\n",
            "# # plt.fill_between(x, predicted - 2 * np.std(predicted), predicted + 2 * np.std(predicted), color='r', alpha=0.2, label='Uncertainty')\n",
            "# plt.title('Regression with Uncertainty')\n",
            "# plt.xlabel('x')\n",
            "# plt.ylabel('y')\n",
            "# plt.legend()\n",
            "# plt.show()"
         ]
      }
   ],
   "metadata": {
      "kaggle": {
         "accelerator": "gpu",
         "dataSources": [],
         "dockerImageVersionId": 31040,
         "isGpuEnabled": true,
         "isInternetEnabled": true,
         "language": "python",
         "sourceType": "notebook"
      },
      "kernelspec": {
         "display_name": "aml",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.13.3"
      },
      "papermill": {
         "default_parameters": {},
         "duration": 4223.060462,
         "end_time": "2025-05-18T10:24:24.455895",
         "environment_variables": {},
         "exception": null,
         "input_path": "__notebook__.ipynb",
         "output_path": "__notebook__.ipynb",
         "parameters": {},
         "start_time": "2025-05-18T09:14:01.395433",
         "version": "2.6.0"
      }
   },
   "nbformat": 4,
   "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21d70f21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T12:35:46.200324Z",
     "iopub.status.busy": "2025-05-26T12:35:46.200119Z",
     "iopub.status.idle": "2025-05-26T12:35:59.451759Z",
     "shell.execute_reply": "2025-05-26T12:35:59.450971Z"
    },
    "papermill": {
     "duration": 13.257903,
     "end_time": "2025-05-26T12:35:59.453159",
     "exception": false,
     "start_time": "2025-05-26T12:35:46.195256",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import v2 as transforms\n",
    "import numpy as np\n",
    "import wandb\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e748769",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T12:35:59.461621Z",
     "iopub.status.busy": "2025-05-26T12:35:59.460893Z",
     "iopub.status.idle": "2025-05-26T12:35:59.464678Z",
     "shell.execute_reply": "2025-05-26T12:35:59.463992Z"
    },
    "papermill": {
     "duration": 0.008794,
     "end_time": "2025-05-26T12:35:59.465720",
     "exception": false,
     "start_time": "2025-05-26T12:35:59.456926",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "generator = torch.Generator().manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e80f7284",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T12:35:59.473513Z",
     "iopub.status.busy": "2025-05-26T12:35:59.472881Z",
     "iopub.status.idle": "2025-05-26T12:35:59.537844Z",
     "shell.execute_reply": "2025-05-26T12:35:59.537067Z"
    },
    "papermill": {
     "duration": 0.069876,
     "end_time": "2025-05-26T12:35:59.539018",
     "exception": false,
     "start_time": "2025-05-26T12:35:59.469142",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a756e483",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T12:35:59.547092Z",
     "iopub.status.busy": "2025-05-26T12:35:59.546653Z",
     "iopub.status.idle": "2025-05-26T12:35:59.557688Z",
     "shell.execute_reply": "2025-05-26T12:35:59.557007Z"
    },
    "papermill": {
     "duration": 0.016285,
     "end_time": "2025-05-26T12:35:59.558701",
     "exception": false,
     "start_time": "2025-05-26T12:35:59.542416",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "class GaussianPosterior(nn.Module):\n",
    "    LOG_SQRT_2PI = 0.5 * np.log(2 * np.pi)\n",
    "\n",
    "    def __init__(self, mu, rho):\n",
    "        super().__init__()\n",
    "\n",
    "        self.mu = nn.Parameter(mu)\n",
    "        self.rho = nn.Parameter(rho)\n",
    "\n",
    "        self.w = None\n",
    "        self.sigma = None\n",
    "\n",
    "        self.normal = torch.distributions.Normal(0, 1)\n",
    "\n",
    "    def sample(self):\n",
    "        epsilon = self.normal.sample(self.mu.size()).to(device)\n",
    "        self.sigma = torch.log1p(torch.exp(self.rho))\n",
    "        self.w = self.mu + self.sigma * epsilon\n",
    "\n",
    "        return self.w\n",
    "\n",
    "    def log_posterior(self):\n",
    "        assert self.w is not None\n",
    "        assert self.sigma is not None\n",
    "\n",
    "        log_posterior = -GaussianPosterior.LOG_SQRT_2PI - torch.log(self.sigma) - ((self.w - self.mu) ** 2) / (2 * self.sigma ** 2)\n",
    "\n",
    "        return log_posterior.sum()\n",
    "\n",
    "\n",
    "class ScaleMixturePrior(nn.Module):\n",
    "\n",
    "    def __init__(self, pi: float, sigma1: float, sigma2: float):\n",
    "        super().__init__()\n",
    "\n",
    "        self.pi = pi\n",
    "        self.normal1 = torch.distributions.Normal(0, sigma1)\n",
    "        self.normal2 = torch.distributions.Normal(0, sigma2)\n",
    "\n",
    "    def log_prior(self, w):\n",
    "        likelihood1 = torch.exp(self.normal1.log_prob(w))\n",
    "        likelihood2 = torch.exp(self.normal2.log_prob(w))\n",
    "\n",
    "        p_mixture = self.pi * likelihood1 + (1 - self.pi) * likelihood2\n",
    "        log_prob = torch.log(p_mixture).sum()\n",
    "\n",
    "        return log_prob\n",
    "\n",
    "\n",
    "class BayesianModule(nn.Module):\n",
    "    pass\n",
    "\n",
    "\n",
    "class BayesLinear(BayesianModule):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "            in_features: int,\n",
    "            out_features: int,\n",
    "            prior_pi: float,\n",
    "            prior_sigma1: float,\n",
    "            prior_sigma2: float\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        w_mu = torch.empty(out_features, in_features).normal_(0.0, 0.01 * (np.log(in_features) + np.log(out_features)), generator=generator)\n",
    "        w_rho = torch.empty(out_features, in_features).normal_(-4.5, 0.001 * (np.log(in_features) + np.log(out_features)))\n",
    "\n",
    "        bias_mu = torch.empty(out_features).normal_(0.0, 0.01 * (np.log(in_features) + np.log(out_features)), generator=generator)\n",
    "        bias_rho = torch.empty(out_features).normal_(-4.5, 0.001 * (np.log(in_features) + np.log(out_features)))\n",
    "\n",
    "        self.w_posterior = GaussianPosterior(w_mu, w_rho)\n",
    "        self.b_posterior = GaussianPosterior(bias_mu, bias_rho)\n",
    "\n",
    "        self.w_prior = ScaleMixturePrior(prior_pi, prior_sigma1, prior_sigma2)\n",
    "        self.b_prior = ScaleMixturePrior(prior_pi, prior_sigma1, prior_sigma2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        w = self.w_posterior.sample()\n",
    "        b = self.b_posterior.sample()\n",
    "\n",
    "        log_prior = self.w_prior.log_prior(w) + self.b_prior.log_prior(b)\n",
    "        log_posterior = self.w_posterior.log_posterior() + self.b_posterior.log_posterior()\n",
    "\n",
    "        self.kl_divergence = log_posterior - log_prior\n",
    "\n",
    "        return F.linear(x, w, b)\n",
    "\n",
    "\n",
    "def minibatch_weight(batch_idx: int, num_batches: int) -> float:\n",
    "    return 1 / num_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fb0748",
   "metadata": {
    "papermill": {
     "duration": 0.003058,
     "end_time": "2025-05-26T12:35:59.564966",
     "exception": false,
     "start_time": "2025-05-26T12:35:59.561908",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# MNIST classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff439a12",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T12:35:59.572061Z",
     "iopub.status.busy": "2025-05-26T12:35:59.571838Z",
     "iopub.status.idle": "2025-05-26T12:35:59.577745Z",
     "shell.execute_reply": "2025-05-26T12:35:59.577060Z"
    },
    "papermill": {
     "duration": 0.010789,
     "end_time": "2025-05-26T12:35:59.578887",
     "exception": false,
     "start_time": "2025-05-26T12:35:59.568098",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MNISTModel(nn.Module):\n",
    "\n",
    "    def __init__(self, in_features=28 * 28, out_features=10, prior_sigma_1=0.1, prior_sigma_2=0.4, prior_pi=1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            BayesLinear(\n",
    "                in_features,\n",
    "                1200,\n",
    "                prior_pi,\n",
    "                prior_sigma_1,\n",
    "                prior_sigma_2\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            BayesLinear(\n",
    "                1200,\n",
    "                1200,\n",
    "                prior_pi,\n",
    "                prior_sigma_1,\n",
    "                prior_sigma_2\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            BayesLinear(\n",
    "                1200,\n",
    "                out_features,\n",
    "                prior_pi,\n",
    "                prior_sigma_1,\n",
    "                prior_sigma_2,\n",
    "            ),\n",
    "            nn.Softmax(dim=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        # print(x)\n",
    "        return x\n",
    "\n",
    "    @property\n",
    "    def kl_divergence(self):\n",
    "        kl = 0\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, BayesianModule):\n",
    "                kl += module.kl_divergence\n",
    "\n",
    "        return kl\n",
    "\n",
    "    def sample_elbo(self, inputs, labels, criterion, num_samples, complexity_cost_weight=1):\n",
    "        loss = 0\n",
    "        for _ in range(num_samples):\n",
    "            outputs = self(inputs)\n",
    "            contr1 = criterion(outputs, labels)\n",
    "            contr2 = self.kl_divergence * complexity_cost_weight\n",
    "            # print(f\"contr1: {contr1}, contr2: {contr2}\")\n",
    "            loss += contr1 + contr2\n",
    "        return loss / num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79438af3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T12:35:59.586716Z",
     "iopub.status.busy": "2025-05-26T12:35:59.586175Z",
     "iopub.status.idle": "2025-05-26T12:35:59.595100Z",
     "shell.execute_reply": "2025-05-26T12:35:59.594408Z"
    },
    "papermill": {
     "duration": 0.013945,
     "end_time": "2025-05-26T12:35:59.596211",
     "exception": false,
     "start_time": "2025-05-26T12:35:59.582266",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(model, train_loader, optimizer, criterion, num_samples=1):\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        kl_weight = minibatch_weight(batch_idx, len(train_loader))\n",
    "\n",
    "        loss = model.sample_elbo(data, target, criterion, num_samples, kl_weight)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "\n",
    "def evaluate(model, val_loader, criterion):\n",
    "    model.eval()\n",
    "\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(val_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "\n",
    "            output = model(data)\n",
    "\n",
    "            preds = torch.argmax(output, 1)\n",
    "            correct += (preds == target).sum().item()\n",
    "\n",
    "            loss = (\n",
    "                criterion(output, target) + model.kl_divergence * minibatch_weight(batch_idx, len(val_loader))\n",
    "            )\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    total = len(val_loader.dataset)\n",
    "    return total_loss / total, (total - correct) / total\n",
    "\n",
    "\n",
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "\n",
    "            output = model(data)\n",
    "\n",
    "            preds = torch.argmax(output, 1)\n",
    "            correct += (preds == target).sum().item()\n",
    "\n",
    "    total = len(test_loader.dataset)\n",
    "    error = (total - correct) / total\n",
    "\n",
    "    # print(f\"Correct: {correct}/{total} ({correct / total:.2%})\")\n",
    "    return error\n",
    "\n",
    "\n",
    "def train(model, train_loader, val_loader, test_loader, optimizer, criterion, num_epochs, num_samples, use_wandb=False):\n",
    "    for epoch in range(num_epochs):\n",
    "        now = time.time()\n",
    "\n",
    "        train_loss = train_one_epoch(model, train_loader, optimizer, criterion, num_samples)\n",
    "        val_loss, val_error = evaluate(model, val_loader, criterion)\n",
    "        test_error = test(model, test_loader)\n",
    "\n",
    "        elapsed = time.time() - now\n",
    "\n",
    "        if use_wandb:\n",
    "            wandb.log({\n",
    "                \"epoch\": epoch,\n",
    "                \"train_loss\": train_loss,\n",
    "                \"val_loss\": val_loss,\n",
    "                \"val_error\": val_error,\n",
    "                \"test_error\": test_error\n",
    "            })\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Error: {val_error:.2%}, Test Error: {test_error:.2%}, Time: {elapsed:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a273b065",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T12:35:59.603593Z",
     "iopub.status.busy": "2025-05-26T12:35:59.603079Z",
     "iopub.status.idle": "2025-05-26T12:35:59.607491Z",
     "shell.execute_reply": "2025-05-26T12:35:59.607010Z"
    },
    "papermill": {
     "duration": 0.009151,
     "end_time": "2025-05-26T12:35:59.608549",
     "exception": false,
     "start_time": "2025-05-26T12:35:59.599398",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_mnist(train_loader, val_loader, test_loader, epochs, lr, num_samples, pi, minus_log_sigma1, minus_log_sigma2, use_wandb=False):\n",
    "    sigma1 = np.exp(-minus_log_sigma1)\n",
    "    sigma2 = np.exp(-minus_log_sigma2)\n",
    "\n",
    "    model = MNISTModel(prior_sigma_1=sigma1, prior_sigma_2=sigma2, prior_pi=pi)\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss(reduction='sum')\n",
    "\n",
    "    if use_wandb:\n",
    "        run = wandb.init(project=\"asi-paper\", name=\"mnist\")\n",
    "\n",
    "    train(model, train_loader, val_loader, test_loader, optimizer, criterion, epochs, num_samples, use_wandb=use_wandb)\n",
    "\n",
    "    if use_wandb:\n",
    "        run.finish()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dbab42a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T12:35:59.615836Z",
     "iopub.status.busy": "2025-05-26T12:35:59.615620Z",
     "iopub.status.idle": "2025-05-26T12:36:01.216342Z",
     "shell.execute_reply": "2025-05-26T12:36:01.215478Z"
    },
    "papermill": {
     "duration": 1.605725,
     "end_time": "2025-05-26T12:36:01.217586",
     "exception": false,
     "start_time": "2025-05-26T12:35:59.611861",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToImage(),\n",
    "    transforms.ToDtype(torch.float32, scale=True),\n",
    "    transforms.Lambda(lambda x: x.view(28 * 28) / 126.0),\n",
    "])\n",
    "\n",
    "\n",
    "mnist_dataset = datasets.MNIST(\n",
    "    root=\"./mnist\",\n",
    "    download=True,\n",
    "    transform=transform,\n",
    "    train=True\n",
    ")\n",
    "# transformed_data = transform(mnist_dataset.data).to(device)\n",
    "# y = mnist_dataset.targets.to(device)\n",
    "# mnist_dataset = torch.utils.data.TensorDataset(transformed_data, y)\n",
    "\n",
    "test_set = datasets.MNIST(\n",
    "    root=\"./mnist\",\n",
    "    download=True,\n",
    "    transform=transform,\n",
    "    train=False\n",
    ")\n",
    "\n",
    "\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(mnist_dataset, [50_000, 10_000], generator=generator)\n",
    "\n",
    "kwargs = {\n",
    "    'batch_size': batch_size,\n",
    "    'num_workers': 1,\n",
    "    'generator': generator,\n",
    "    'pin_memory': True,\n",
    "}\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    shuffle=True,\n",
    "    **kwargs\n",
    ")\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset,\n",
    "    shuffle=False,\n",
    "    **kwargs\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_set,\n",
    "    shuffle=False,\n",
    "    **kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a95c2b",
   "metadata": {
    "papermill": {
     "duration": 0.003903,
     "end_time": "2025-05-26T12:36:01.225679",
     "exception": false,
     "start_time": "2025-05-26T12:36:01.221776",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Grid search with wandb\n",
    "Uncomment the code below to run a grid search and log the results to wandb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b947162f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T12:36:01.234073Z",
     "iopub.status.busy": "2025-05-26T12:36:01.233869Z",
     "iopub.status.idle": "2025-05-26T12:36:01.237403Z",
     "shell.execute_reply": "2025-05-26T12:36:01.236915Z"
    },
    "papermill": {
     "duration": 0.009038,
     "end_time": "2025-05-26T12:36:01.238444",
     "exception": false,
     "start_time": "2025-05-26T12:36:01.229406",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from kaggle_secrets import UserSecretsClient\n",
    "# user_secrets = UserSecretsClient()\n",
    "# key = user_secrets.get_secret('wand-api-key-asi')\n",
    "# sweep_continue = user_secrets.get_secret('asi-mnist-sweep-id')\n",
    "\n",
    "# wandb.login(key=key)\n",
    "\n",
    "\n",
    "# def train_wrapper():\n",
    "#     with wandb.init(project=\"asi-paper\") as run:\n",
    "#         model = train_mnist(\n",
    "#             train_loader,\n",
    "#             val_loader,\n",
    "#             test_loader,\n",
    "#             epochs=10,\n",
    "#             lr=run.config.lr,\n",
    "#             num_samples=run.config.sample_nbr,\n",
    "#             pi=run.config.pi,\n",
    "#             minus_log_sigma1=run.config.min_log_sigma1,\n",
    "#             minus_log_sigma2=run.config.min_log_sigma2,\n",
    "#             use_wandb=True\n",
    "#         )\n",
    "\n",
    "#     return model\n",
    "\n",
    "\n",
    "# # sweep_configuration = {\n",
    "# #     \"method\": \"grid\",\n",
    "# #     \"metric\": {\"goal\": \"minimize\", \"name\": \"val_error\"},\n",
    "# #     'name': \"sweep-mnist\",\n",
    "# #     \"parameters\": {\n",
    "# #         \"lr\": {'values': [1e-3, 1e-4, 1e-5]},\n",
    "# #         \"sample_nbr\": {'values': [1, 2, 3, 5]},\n",
    "# #         \"pi\": {'values': [0.25, 0.5, 0.75]},\n",
    "# #         \"min_log_sigma1\": {'values': [0, 1, 2]},\n",
    "# #         \"min_log_sigma2\": {'values': [6, 7, 8]},\n",
    "# #     },\n",
    "# # }\n",
    "\n",
    "# # sweep_id = wandb.sweep(sweep=sweep_configuration, project=\"asi-paper\")\n",
    "# # print(f\"Sweep ID: {sweep_id}\")\n",
    "# wandb.agent(sweep_continue, function=train_wrapper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a946f59",
   "metadata": {
    "papermill": {
     "duration": 0.003661,
     "end_time": "2025-05-26T12:36:01.245943",
     "exception": false,
     "start_time": "2025-05-26T12:36:01.242282",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Manual training\n",
    "Uncomment the code below to train the model with specified hyperparameters and save it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766baab0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T12:36:01.254299Z",
     "iopub.status.busy": "2025-05-26T12:36:01.253798Z",
     "iopub.status.idle": "2025-05-26T13:05:41.981229Z",
     "shell.execute_reply": "2025-05-26T13:05:41.980616Z"
    },
    "papermill": {
     "duration": 1780.732766,
     "end_time": "2025-05-26T13:05:41.982390",
     "exception": false,
     "start_time": "2025-05-26T12:36:01.249624",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Train Loss: 21300.8569, Val Loss: 695.3979, Val Error: 23.28%, Test Error: 23.45%, Time: 32.73s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# from kaggle_secrets import UserSecretsClient\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# user_secrets = UserSecretsClient()\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# key = user_secrets.get_secret('wand-api-key-asi')\u001b[39;00m\n\u001b[32m      4\u001b[39m \n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# wandb.login(key=key)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m model = \u001b[43mtrain_mnist\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1e-3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpi\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mminus_log_sigma1\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mminus_log_sigma2\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_wandb\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# torch.save(model.state_dict(), \"mnist_model.pt\")\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36mtrain_mnist\u001b[39m\u001b[34m(train_loader, val_loader, test_loader, epochs, lr, num_samples, pi, minus_log_sigma1, minus_log_sigma2, use_wandb)\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m use_wandb:\n\u001b[32m     12\u001b[39m     run = wandb.init(project=\u001b[33m\"\u001b[39m\u001b[33masi-paper\u001b[39m\u001b[33m\"\u001b[39m, name=\u001b[33m\"\u001b[39m\u001b[33mmnist\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_wandb\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_wandb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m use_wandb:\n\u001b[32m     17\u001b[39m     run.finish()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 74\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(model, train_loader, val_loader, test_loader, optimizer, criterion, num_epochs, num_samples, use_wandb)\u001b[39m\n\u001b[32m     72\u001b[39m train_loss = train_one_epoch(model, train_loader, optimizer, criterion, num_samples)\n\u001b[32m     73\u001b[39m val_loss, val_error = evaluate(model, val_loader, criterion)\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m test_error = \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     76\u001b[39m elapsed = time.time() - now\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m use_wandb:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 56\u001b[39m, in \u001b[36mtest\u001b[39m\u001b[34m(model, test_loader)\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m data, target \u001b[38;5;129;01min\u001b[39;00m test_loader:\n\u001b[32m     54\u001b[39m     data, target = data.to(device), target.to(device)\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m     output = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     58\u001b[39m     preds = torch.argmax(output, \u001b[32m1\u001b[39m)\n\u001b[32m     59\u001b[39m     correct += (preds == target).sum().item()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/aml/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/aml/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 34\u001b[39m, in \u001b[36mMNISTModel.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m     x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     35\u001b[39m     \u001b[38;5;66;03m# print(x)\u001b[39;00m\n\u001b[32m     36\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/aml/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/aml/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/aml/lib/python3.13/site-packages/torch/nn/modules/container.py:250\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    249\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/aml/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/aml/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 79\u001b[39m, in \u001b[36mBayesLinear.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m     w = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mw_posterior\u001b[49m\u001b[43m.\u001b[49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m     b = \u001b[38;5;28mself\u001b[39m.b_posterior.sample()\n\u001b[32m     82\u001b[39m     log_prior = \u001b[38;5;28mself\u001b[39m.w_prior.log_prior(w) + \u001b[38;5;28mself\u001b[39m.b_prior.log_prior(b)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 16\u001b[39m, in \u001b[36mGaussianPosterior.sample\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msample\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m     epsilon = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnormal\u001b[49m\u001b[43m.\u001b[49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmu\u001b[49m\u001b[43m.\u001b[49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m.to(device)\n\u001b[32m     17\u001b[39m     \u001b[38;5;28mself\u001b[39m.sigma = torch.log1p(torch.exp(\u001b[38;5;28mself\u001b[39m.rho))\n\u001b[32m     18\u001b[39m     \u001b[38;5;28mself\u001b[39m.w = \u001b[38;5;28mself\u001b[39m.mu + \u001b[38;5;28mself\u001b[39m.sigma * epsilon\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/aml/lib/python3.13/site-packages/torch/distributions/normal.py:73\u001b[39m, in \u001b[36mNormal.sample\u001b[39m\u001b[34m(self, sample_shape)\u001b[39m\n\u001b[32m     71\u001b[39m shape = \u001b[38;5;28mself\u001b[39m._extended_shape(sample_shape)\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnormal\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexpand\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscale\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexpand\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from kaggle_secrets import UserSecretsClient\n",
    "user_secrets = UserSecretsClient()\n",
    "key = user_secrets.get_secret('wand-api-key-asi')\n",
    "\n",
    "wandb.login(key=key)\n",
    "\n",
    "model = train_mnist(train_loader, val_loader, test_loader, epochs=50, lr=1e-3, num_samples=3, pi=0.5, minus_log_sigma1=0, minus_log_sigma2=6, use_wandb=False)\n",
    "torch.save(model.state_dict(), \"mnist_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e377bb4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T13:05:41.996939Z",
     "iopub.status.busy": "2025-05-26T13:05:41.996384Z",
     "iopub.status.idle": "2025-05-26T13:05:41.999859Z",
     "shell.execute_reply": "2025-05-26T13:05:41.999272Z"
    },
    "papermill": {
     "duration": 0.011692,
     "end_time": "2025-05-26T13:05:42.000928",
     "exception": false,
     "start_time": "2025-05-26T13:05:41.989236",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model = MNISTModel(prior_sigma_1=np.exp(-1), prior_sigma_2=np.exp(-7), prior_pi=0.75)\n",
    "# model.to(device)\n",
    "# model.load_state_dict(torch.load(\"mnist_model.pt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9d0709",
   "metadata": {
    "papermill": {
     "duration": 0.006091,
     "end_time": "2025-05-26T13:05:42.013255",
     "exception": false,
     "start_time": "2025-05-26T13:05:42.007164",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Regression curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fb5b51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T13:05:42.026529Z",
     "iopub.status.busy": "2025-05-26T13:05:42.026121Z",
     "iopub.status.idle": "2025-05-26T13:05:42.032495Z",
     "shell.execute_reply": "2025-05-26T13:05:42.031818Z"
    },
    "papermill": {
     "duration": 0.014239,
     "end_time": "2025-05-26T13:05:42.033634",
     "exception": false,
     "start_time": "2025-05-26T13:05:42.019395",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_samples(num_samples):\n",
    "    eps = np.random.normal(0, 0.02, num_samples)\n",
    "    x = np.linspace(0, 0.5, num_samples)\n",
    "    y = x + 0.3 * np.sin(2 * np.pi * (x + eps)) + 0.3 * np.sin(4 * np.pi * (x + eps))\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def save_samples(x, y, filename):\n",
    "    df = pd.DataFrame({'x': x, 'y': y})\n",
    "    df.to_csv(filename, index=False)\n",
    "\n",
    "\n",
    "def load_samples(filename):\n",
    "    df = pd.read_csv(filename)\n",
    "    x = df['x'].values\n",
    "    y = df['y'].values\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def plot_samples(x, y):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(x, y, 'kx', label='Generated Samples')\n",
    "    plt.title('Generated Samples')\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# x, y = generate_samples(1000)\n",
    "# save_samples(x, y, 'regression_samples.csv')\n",
    "\n",
    "\n",
    "# x, y = load_samples('regression_samples.csv')\n",
    "# plot_samples(x, y)\n",
    "\n",
    "# X_tensor = torch.tensor(x, dtype=torch.float32).view(-1, 1).to(device)\n",
    "# y_tensor = torch.tensor(y, dtype=torch.float32).view(-1, 1).to(device)\n",
    "\n",
    "# train_dataset = torch.utils.data.TensorDataset(X_tensor[:800], y_tensor[:800])\n",
    "# val_dataset = torch.utils.data.TensorDataset(X_tensor[800:], y_tensor[800:])\n",
    "\n",
    "\n",
    "# kwargs = {\n",
    "#     'batch_size': batch_size,\n",
    "#     'generator': generator,\n",
    "# }\n",
    "\n",
    "# train_loader = torch.utils.data.DataLoader(\n",
    "#     train_dataset,\n",
    "#     shuffle=True,\n",
    "#     **kwargs\n",
    "# )\n",
    "# val_loader = torch.utils.data.DataLoader(\n",
    "#     val_dataset,\n",
    "#     shuffle=False,\n",
    "#     **kwargs\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0bdb22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T13:05:42.047172Z",
     "iopub.status.busy": "2025-05-26T13:05:42.046762Z",
     "iopub.status.idle": "2025-05-26T13:05:42.051434Z",
     "shell.execute_reply": "2025-05-26T13:05:42.050790Z"
    },
    "papermill": {
     "duration": 0.012495,
     "end_time": "2025-05-26T13:05:42.052411",
     "exception": false,
     "start_time": "2025-05-26T13:05:42.039916",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RegressionModel(nn.Module):\n",
    "    def __init__(self, in_features=1, out_features=1, prior_sigma_1=0.1, prior_sigma_2=0.4, prior_pi=1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            BayesLinear(\n",
    "                in_features,\n",
    "                200,\n",
    "                prior_pi,\n",
    "                prior_sigma_1,\n",
    "                prior_sigma_2\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            BayesLinear(\n",
    "                200,\n",
    "                200,\n",
    "                prior_pi,\n",
    "                prior_sigma_1,\n",
    "                prior_sigma_2\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            BayesLinear(\n",
    "                200,\n",
    "                out_features,\n",
    "                prior_pi,\n",
    "                prior_sigma_1,\n",
    "                prior_sigma_2,\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d81436f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T13:05:42.066131Z",
     "iopub.status.busy": "2025-05-26T13:05:42.065957Z",
     "iopub.status.idle": "2025-05-26T13:05:42.072023Z",
     "shell.execute_reply": "2025-05-26T13:05:42.071465Z"
    },
    "papermill": {
     "duration": 0.013837,
     "end_time": "2025-05-26T13:05:42.072964",
     "exception": false,
     "start_time": "2025-05-26T13:05:42.059127",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_regression(regressor, X, y, samples=100, std_multiplier=2):\n",
    "    preds = [regressor(X) for _ in range(samples)]\n",
    "    preds = torch.stack(preds)\n",
    "    means = preds.mean(axis=0)\n",
    "    stds = preds.std(axis=0)\n",
    "    ci_upper = means + (std_multiplier * stds)\n",
    "    ci_lower = means - (std_multiplier * stds)\n",
    "    ci_acc = (ci_lower <= y) * (ci_upper >= y)\n",
    "    ci_acc = ci_acc.float().mean()\n",
    "    return ci_acc, (ci_upper >= y).float().mean(), (ci_lower <= y).float().mean()\n",
    "\n",
    "\n",
    "def train_regression(model, train_loader, val_loader, optimizer, criterion, num_epochs, num_samples, use_wandb=False):\n",
    "    for epoch in range(num_epochs):\n",
    "        now = time.time()\n",
    "\n",
    "        train_loss = train_one_epoch(model, train_loader, optimizer, criterion, num_samples)\n",
    "        ci_acc, ci_upper, ci_lower = evaluate_regression(model, val_loader.dataset.tensors[0], val_loader.dataset.tensors[1])\n",
    "\n",
    "        elapsed = time.time() - now\n",
    "\n",
    "        if use_wandb:\n",
    "            wandb.log({\n",
    "                \"epoch\": epoch,\n",
    "                \"train_loss\": train_loss,\n",
    "                \"ci_acc\": ci_acc,\n",
    "                \"ci_upper\": ci_upper,\n",
    "                \"ci_lower\": ci_lower,\n",
    "            })\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Train Loss: {train_loss:.4f}, CI acc: {ci_acc}, CI upper acc: {ci_upper}, CI lower acc: {ci_lower} Time: {elapsed:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd6d69a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T13:05:42.086071Z",
     "iopub.status.busy": "2025-05-26T13:05:42.085897Z",
     "iopub.status.idle": "2025-05-26T13:05:42.089979Z",
     "shell.execute_reply": "2025-05-26T13:05:42.089464Z"
    },
    "papermill": {
     "duration": 0.011782,
     "end_time": "2025-05-26T13:05:42.091003",
     "exception": false,
     "start_time": "2025-05-26T13:05:42.079221",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_regression_model(train_loader, val_loader, epochs, lr, num_samples, pi, minus_log_sigma1, minus_log_sigma2, use_wandb=False):\n",
    "    sigma1 = np.exp(-minus_log_sigma1)\n",
    "    sigma2 = np.exp(-minus_log_sigma2)\n",
    "\n",
    "    model = RegressionModel(1, 1, prior_sigma_1=sigma1, prior_sigma_2=sigma2, prior_pi=pi)\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # if use_wandb:\n",
    "    #     run = wandb.init(project=\"asi-paper\", name=\"regression\")\n",
    "\n",
    "    train_regression(model, train_loader, val_loader, optimizer, criterion, epochs, num_samples, use_wandb=use_wandb)\n",
    "\n",
    "    # if use_wandb:\n",
    "    #     run.finish()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83ec3b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T13:05:42.104110Z",
     "iopub.status.busy": "2025-05-26T13:05:42.103937Z",
     "iopub.status.idle": "2025-05-26T13:05:42.107468Z",
     "shell.execute_reply": "2025-05-26T13:05:42.106817Z"
    },
    "papermill": {
     "duration": 0.011564,
     "end_time": "2025-05-26T13:05:42.108805",
     "exception": false,
     "start_time": "2025-05-26T13:05:42.097241",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from kaggle_secrets import UserSecretsClient\n",
    "# user_secrets = UserSecretsClient()\n",
    "# key = user_secrets.get_secret('wand-api-key-asi')\n",
    "\n",
    "# wandb.login(key=key)\n",
    "\n",
    "\n",
    "# def train_wrapper():\n",
    "#     with wandb.init(project=\"asi-paper\") as run:\n",
    "#         model = train_regression_model(\n",
    "#             train_loader,\n",
    "#             val_loader,\n",
    "#             epochs=15,\n",
    "#             lr=run.config.lr,\n",
    "#             num_samples=run.config.sample_nbr,\n",
    "#             pi=run.config.pi,\n",
    "#             minus_log_sigma1=run.config.min_log_sigma1,\n",
    "#             minus_log_sigma2=run.config.min_log_sigma2,\n",
    "#             use_wandb=True\n",
    "#         )\n",
    "\n",
    "#     return model\n",
    "\n",
    "\n",
    "# sweep_configuration = {\n",
    "#     \"method\": \"bayes\",\n",
    "#     \"metric\": {\"goal\": \"maximize\", \"name\": \"ci_acc\"},\n",
    "#     'name': \"sweep-regression\",\n",
    "#     \"parameters\": {\n",
    "#         \"lr\": {'min': 1e-5, 'max': 1e-2},\n",
    "#         \"sample_nbr\": {'min': 1, 'max': 10},\n",
    "#         \"pi\": {'min': 0.25, 'max': 0.75},\n",
    "#         \"min_log_sigma1\": {'min': 0, 'max': 2},\n",
    "#         \"min_log_sigma2\": {'min': 6, 'max': 8},\n",
    "#     },\n",
    "# }\n",
    "\n",
    "# sweep_id = wandb.sweep(sweep=sweep_configuration, project=\"asi-paper\")\n",
    "# wandb.agent(sweep_id, function=train_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec68ec5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T13:05:42.122909Z",
     "iopub.status.busy": "2025-05-26T13:05:42.122497Z",
     "iopub.status.idle": "2025-05-26T13:05:42.125649Z",
     "shell.execute_reply": "2025-05-26T13:05:42.124989Z"
    },
    "papermill": {
     "duration": 0.011148,
     "end_time": "2025-05-26T13:05:42.126674",
     "exception": false,
     "start_time": "2025-05-26T13:05:42.115526",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model = train_regression_model(train_loader, val_loader, epochs=10, lr=1e-3, num_samples=1, pi=0.5, minus_log_sigma1=0.5, minus_log_sigma2=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc67418",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-26T13:05:42.139789Z",
     "iopub.status.busy": "2025-05-26T13:05:42.139558Z",
     "iopub.status.idle": "2025-05-26T13:05:42.142632Z",
     "shell.execute_reply": "2025-05-26T13:05:42.141970Z"
    },
    "papermill": {
     "duration": 0.010796,
     "end_time": "2025-05-26T13:05:42.143725",
     "exception": false,
     "start_time": "2025-05-26T13:05:42.132929",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model.eval()\n",
    "# predicted = model(X_tensor).cpu().detach().numpy()\n",
    "\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(x, y, 'kx', label='Generated Samples')\n",
    "# plt.plot(x, predicted, 'r-', label='Predicted Mean')\n",
    "# # plt.fill_between(x, predicted - 2 * np.std(predicted), predicted + 2 * np.std(predicted), color='r', alpha=0.2, label='Uncertainty')\n",
    "# plt.title('Regression with Uncertainty')\n",
    "# plt.xlabel('x')\n",
    "# plt.ylabel('y')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "aml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1802.772371,
   "end_time": "2025-05-26T13:05:44.868862",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-26T12:35:42.096491",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
